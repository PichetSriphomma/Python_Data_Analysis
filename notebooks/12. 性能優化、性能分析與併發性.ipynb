{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. 性能優化、性能分析與併發性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify import accuracy\n",
    "from lprof_hack import profile\n",
    "\n",
    "@profile\n",
    "def label_docs():\n",
    "    docs = [(list(movie_reviews.words(fid)), cat)\n",
    "            for cat in movie_reviews.categories()\n",
    "            for fid in movie_reviews.fileids(cat)]\n",
    "    random.seed(42)\n",
    "    random.shuffle(docs)\n",
    "\n",
    "    return docs\n",
    "\n",
    "@profile\n",
    "def isStopWord(word):\n",
    "    return word in sw or len(word) == 1\n",
    "\n",
    "@profile\n",
    "def filter_corpus():\n",
    "    review_words = movie_reviews.words()\n",
    "    print(\"# Review Words\", len(review_words))\n",
    "    res = [w.lower() for w in review_words if not isStopWord(w.lower())]\n",
    "    print(\"# After filter\", len(res))\n",
    "\n",
    "    return res\n",
    "\n",
    "@profile\n",
    "def select_word_features(corpus):\n",
    "    words = FreqDist(corpus)\n",
    "    N = int(.02 * len(list(words.keys())))\n",
    "    return list(words.keys())[:N]\n",
    "\n",
    "@profile\n",
    "def doc_features(doc):\n",
    "    doc_words = FreqDist(w for w in doc if not isStopWord(w))\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['count (%s)' % word] = (doc_words.get(word, 0))\n",
    "    return features\n",
    "\n",
    "@profile\n",
    "def make_features(docs):\n",
    "    return [(doc_features(d), c) for (d,c) in docs]\n",
    "\n",
    "@profile\n",
    "def split_data(sets):\n",
    "    return sets[200:], sets[:200]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    labeled_docs = label_docs()\n",
    "\n",
    "    sw = set(stopwords.words('english'))\n",
    "    filtered = filter_corpus()\n",
    "    word_features = select_word_features(filtered)\n",
    "    featuresets = make_features(labeled_docs)\n",
    "    train_set, test_set = split_data(featuresets)\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    print(\"Accuracy\", accuracy(classifier, test_set))\n",
    "    print(classifier.show_most_informative_features())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4 multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import random_integers\n",
    "from numpy.random import randn, randint\n",
    "import numpy as np\n",
    "import timeit\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def simulate(size):\n",
    "    n = 0\n",
    "    mean = 0\n",
    "    M2 = 0\n",
    "\n",
    "    speed = randn(10000)\n",
    "\n",
    "    for i in range(1000): \n",
    "        n = n + 1\n",
    "        indices = randint(0, len(speed)-1, size=size)\n",
    "        x = (1 + speed[indices]).prod()\n",
    "        delta = x - mean\n",
    "        mean = mean + delta/n\n",
    "        M2 = M2 + delta*(x - mean)\n",
    "\n",
    "    return mean\n",
    "\n",
    "def serial():\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    for i in range(10, 50):\n",
    "        simulate(i)\n",
    "    \n",
    "    end = timeit.default_timer() - start\n",
    "    print(\"Serial time\", end)\n",
    "\n",
    "    return end\n",
    "\n",
    "def parallel(nprocs):\n",
    "    start = timeit.default_timer()\n",
    "    p = mp.Pool(nprocs)\n",
    "    print(nprocs, \"Pool creation time\", timeit.default_timer() - start)\n",
    "\n",
    "    p.map(simulate, [i for i in range(10, 50)])\n",
    "    p.close()\n",
    "    p.join()\n",
    "\n",
    "    end = timeit.default_timer() - start\n",
    "    print(nprocs, \"Parallel time\", end)\n",
    "    return end\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ratios = []\n",
    "    baseline = serial()\n",
    "\n",
    "    for i in range(1, mp.cpu_count()):\n",
    "        ratios.append(baseline/parallel(i))\n",
    "\n",
    "    plt.xlabel('# processes')\n",
    "    plt.ylabel('Serial/Parallel')\n",
    "    n = np.arange(1, mp.cpu_count())\n",
    "    plt.plot(n, ratios)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.5 Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7fbd46c55574>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "from numpy.random import random_integers\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import timeit\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def simulate(size):\n",
    "    n = 0\n",
    "    mean = 0\n",
    "    M2 = 0\n",
    "\n",
    "    speed = randn(10000)\n",
    "\n",
    "    for i in range(1000): \n",
    "        n = n + 1\n",
    "        indices = random_integers(0, len(speed)-1, size=size)\n",
    "        x = (1 + speed[indices]).prod()\n",
    "        delta = x - mean\n",
    "        mean = mean + delta/n\n",
    "        M2 = M2 + delta*(x - mean)\n",
    "\n",
    "    return mean\n",
    "\n",
    "def serial():\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    for i in range(10, 50):\n",
    "        simulate(i)\n",
    "    \n",
    "    end = timeit.default_timer() - start\n",
    "    print(\"Serial time\", end)\n",
    "\n",
    "    return end\n",
    "\n",
    "def parallel(nprocs):\n",
    "    start = timeit.default_timer()\n",
    "    Parallel(nprocs)(delayed(simulate)(i) for i in range(10, 50))\n",
    "\n",
    "    end = timeit.default_timer() - start\n",
    "    print(nprocs, \"Parallel time\", end)\n",
    "    return end\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ratios = []\n",
    "    baseline = serial()\n",
    "\n",
    "    for i in range(1, mp.cpu_count()):\n",
    "        ratios.append(baseline/parallel(i))\n",
    "\n",
    "    plt.xlabel('# processes')\n",
    "    plt.ylabel('Serial/Parallel')\n",
    "    plt.plot(np.arange(1, mp.cpu_count()), ratios)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'mpi4py'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5d1c0993c61c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmpi4py\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMPI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom_integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'mpi4py'"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "from numpy.random import random_integers\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import bottleneck as bn\n",
    "import logging\n",
    "\n",
    "\n",
    "def jackknife(a, parallel=True):\n",
    "    data_loader = sm.datasets.sunspots.load_pandas()\n",
    "    vals = data_loader.data['SUNACTIVITY'].values\n",
    "\n",
    "    func, _ = bn.func.nanmean_selector(vals, axis=0)\n",
    "    results = []\n",
    "\n",
    "    for i in a:\n",
    "        tmp = np.array(vals.tolist())\n",
    "        tmp[i] = np.nan\n",
    "        results.append(func(tmp))\n",
    "\n",
    "    results = np.array(results)\n",
    "\n",
    "    if parallel:\n",
    "        comm = MPI.COMM_WORLD\n",
    "        rcvBuf = np.zeros(0.0, 'd')\n",
    "        comm.gather([results, MPI.DOUBLE], [rcvBuf, MPI.DOUBLE])\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    skiplist = np.arange(39, dtype='int')\n",
    "    print(jackknife(skiplist, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
